{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Konstanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNINGRATE = 1e-4\n",
    "EPOCHS = 20\n",
    "BATCHSIZE = 32\n",
    "\n",
    "dir = r\"datasets\"\n",
    "categories = [\"mask\", \"noMask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproses Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading images...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmad Aziz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"[Loading images...]\")\n",
    "data = []\n",
    "labels = []\n",
    "for category in categories:\n",
    "\tpath = os.path.join(dir, category)\n",
    "\tfor img in os.listdir(path):\n",
    "\t\timg_path = os.path.join(path, img)\n",
    "\t\timage = load_img(img_path, target_size=(224, 224))\n",
    "\t\timage = img_to_array(image)\n",
    "\t\timage = preprocess_input(image)\n",
    "\n",
    "\t\tdata.append(image)\n",
    "\t\tlabels.append(category)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\theight_shift_range=0.2,\n",
    "\twidth_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Head Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Compiling model...]\n"
     ]
    }
   ],
   "source": [
    "print(\"[Compiling model...]\")\n",
    "opt = Adam(learning_rate=LEARNINGRATE, decay=LEARNINGRATE / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 83s 811ms/step - loss: 0.4188 - accuracy: 0.8388 - val_loss: 0.1681 - val_accuracy: 0.9778\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 82s 868ms/step - loss: 0.1607 - accuracy: 0.9598 - val_loss: 0.0837 - val_accuracy: 0.9844\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 87s 915ms/step - loss: 0.1028 - accuracy: 0.9763 - val_loss: 0.0625 - val_accuracy: 0.9844\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 86s 911ms/step - loss: 0.0780 - accuracy: 0.9789 - val_loss: 0.0522 - val_accuracy: 0.9844\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 92s 970ms/step - loss: 0.0640 - accuracy: 0.9802 - val_loss: 0.0474 - val_accuracy: 0.9857\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 101s 1s/step - loss: 0.0588 - accuracy: 0.9835 - val_loss: 0.0444 - val_accuracy: 0.9857\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 89s 942ms/step - loss: 0.0543 - accuracy: 0.9855 - val_loss: 0.0419 - val_accuracy: 0.9857\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 87s 917ms/step - loss: 0.0463 - accuracy: 0.9862 - val_loss: 0.0386 - val_accuracy: 0.9857\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 86s 909ms/step - loss: 0.0434 - accuracy: 0.9868 - val_loss: 0.0367 - val_accuracy: 0.9870\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 76s 796ms/step - loss: 0.0408 - accuracy: 0.9881 - val_loss: 0.0375 - val_accuracy: 0.9883\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 89s 942ms/step - loss: 0.0369 - accuracy: 0.9898 - val_loss: 0.0370 - val_accuracy: 0.9883\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 81s 855ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 0.0354 - val_accuracy: 0.9870\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 107s 1s/step - loss: 0.0328 - accuracy: 0.9904 - val_loss: 0.0362 - val_accuracy: 0.9870\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 113s 1s/step - loss: 0.0366 - accuracy: 0.9911 - val_loss: 0.0362 - val_accuracy: 0.9870\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 106s 1s/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0363 - val_accuracy: 0.9870\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 103s 1s/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.0332 - val_accuracy: 0.9870\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 97s 1s/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.0340 - val_accuracy: 0.9870\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 99s 1s/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 0.0376 - val_accuracy: 0.9857\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 104s 1s/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 0.0356 - val_accuracy: 0.9870\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 99s 1s/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.0351 - val_accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BATCHSIZE),\n",
    "\tsteps_per_epoch=len(trainX) // BATCHSIZE,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BATCHSIZE,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on the Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicting...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mask       0.99      0.98      0.99       383\n",
      "      noMask       0.98      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Predicting...\")\n",
    "predIdx = model.predict(testX, batch_size=BATCHSIZE)\n",
    "predIdx = np.argmax(predIdx, axis=1)\n",
    "\n",
    "print(classification_report(testY.argmax(axis=1), predIdx, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saving mask detector model...]\n"
     ]
    }
   ],
   "source": [
    "# save trained model\n",
    "print(\"[Saving mask detector model...]\")\n",
    "model.save(\"maskModel/trainedDetection.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ahmad Aziz\\Data\\python-nextdev\\final_project\\maskDetection.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ahmad%20Aziz/Data/python-nextdev/final_project/maskDetection.ipynb#ch0000019?line=2'>3</a>\u001b[0m N \u001b[39m=\u001b[39m EPOCHS\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ahmad%20Aziz/Data/python-nextdev/final_project/maskDetection.ipynb#ch0000019?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mstyle\u001b[39m.\u001b[39muse(\u001b[39m\"\u001b[39m\u001b[39mggplot\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ahmad%20Aziz/Data/python-nextdev/final_project/maskDetection.ipynb#ch0000019?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39;49mfigure()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ahmad%20Aziz/Data/python-nextdev/final_project/maskDetection.ipynb#ch0000019?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, N), H\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ahmad%20Aziz/Data/python-nextdev/final_project/maskDetection.ipynb#ch0000019?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, N), H\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ead8c2e1cfd2cd0815b1164870e6eed5ce9a96d6273275cb71190e504ef4afad"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

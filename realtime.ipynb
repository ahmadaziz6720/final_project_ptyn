{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def detectMask(frame, faceNet, maskNet):\n",
    "\t# set dimensions\n",
    "\th, w = frame.shape[:2]\n",
    "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224), (104.0, 177.0, 123.0))\n",
    "\n",
    "\tfaceNet.setInput(blob)\n",
    "\tdetections = faceNet.forward()\n",
    "\n",
    "\tfaces = []\n",
    "\tpoints = []\n",
    "\tdetects = []\n",
    "\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\tprobability = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# filter\n",
    "\t\tif probability > 0.5:\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\tx1, y1, x2, y2 = box.astype(\"int\")\n",
    "\t\t\tx1, y1 = max(0, x1), max(0, y1)\n",
    "\t\t\tx2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
    "\n",
    "\t\t\t# preprocess face\n",
    "\t\t\tface = frame[y1:y2, x1:x2]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\n",
    "\t\t\tfaces.append(face)\n",
    "\t\t\tpoints.append((x1, y1, x2, y2))\n",
    "\n",
    "\tif len(faces) > 0:\n",
    "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
    "\t\tdetects = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "\treturn (points, detects)\n",
    "\n",
    "\n",
    "# for display\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# face detector model\n",
    "ProtoPath = r\"faceModel\\deploy.prototxt\"\n",
    "WeightsPath = r\"faceModel\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(ProtoPath, WeightsPath)\n",
    "\n",
    "# trained mask detection model\n",
    "maskNet = load_model(\"maskModel/trainedDetection.model\")\n",
    "\n",
    "\n",
    "print(\"----------------------START----------------------\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "\tret, frame = cap.read()\n",
    "\n",
    "\tpoints, detects = detectMask(frame, faceNet, maskNet)\n",
    "\n",
    "\tfor (box, pred) in zip(points, detects):\n",
    "\t\tx1, y1, x2, y2 = box\n",
    "\t\tmask, noMask = pred\n",
    "\n",
    "\t\t# set label and probability\n",
    "\t\tlabel = \"Mask\" if mask > noMask else \"No Mask\"\n",
    "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, noMask) * 100)\n",
    "\t\tcolor = green if mask > noMask else red\n",
    "\n",
    "\t\t# display\n",
    "\t\tcv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\t\tcv2.putText(frame, label, (x1, y1 - 10), font, 0.45, color, 2)\n",
    "\n",
    "\tcv2.imshow(\"Mask Detection\", frame)\n",
    "\n",
    "\tif (cv2.waitKey(1) & 0xFF) == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
